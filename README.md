<div align="center">

# ğŸš€ CO-Benchmark-Datasets

**Comprehensive Benchmark Datasets for Reinforcement Learning in Combinatorial Optimization**

[![Version](https://img.shields.io/badge/version-1.0.1-blue.svg)](https://github.com/Boulea7/CO-Benchmark-Datasets)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/)
[![Issues](https://img.shields.io/github/issues/Boulea7/CO-Benchmark-Datasets)](https://github.com/Boulea7/CO-Benchmark-Datasets/issues)
[![Size](https://img.shields.io/github/repo-size/Boulea7/CO-Benchmark-Datasets)](https://github.com/Boulea7/CO-Benchmark-Datasets)
[![Dataset Size](https://img.shields.io/badge/datasets-447%20files-orange.svg)]()

## ğŸ¯ Research Focus: NP-Hard Combinatorial Optimization Problems

**Specialized benchmark datasets for advancing reinforcement learning algorithms in classical NP-Hard problems**

</div>

---

## ğŸ“‹ Abstract

This repository provides a comprehensive collection of standardized, high-quality benchmark datasets specifically designed for evaluating reinforcement learning algorithms on classical combinatorial optimization problems. Our benchmark suite focuses on three fundamental NP-Hard problems that serve as critical testbeds for algorithmic innovation:

- ğŸ”„ **Graph Partitioning** - Minimize cut edges while maintaining balance constraints
- ğŸ¨ **Graph Coloring** - Minimize chromatic number while avoiding adjacent conflicts
- ğŸ”¢ **Number Partitioning** - Balance subset assignments to minimize maximum completion time

These datasets are meticulously curated from multiple authoritative sources, processed into unified formats, and optimized for machine learning workflows, providing the research community with essential tools for developing and evaluating next-generation RL algorithms.

## ğŸ“š Table of Contents

- [Abstract](#-abstract)
- [Key Features](#-key-features)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Dataset Overview](#-dataset-overview)
- [Algorithm Baselines](#-algorithm-baselines)
- [Data Sources](#-data-sources)
- [Usage Guidelines](#-usage-guidelines)
- [Performance Benchmarks](#-performance-benchmarks)
- [Repository Structure](#-repository-structure)
- [Contributing](#-contributing)
- [Citation](#-citation)
- [License](#-license)
- [Acknowledgments](#-acknowledgments)

## âœ¨ Key Features

### ğŸ”§ **Technical Excellence**
- **Unified Format Standard**: All datasets converted to consistent text format following RLSolver competition specifications
- **Scalable Size Classification**: Systematic categorization (tiny/small/medium/large/xlarge) for progressive algorithm development
- **High Compression Ratio**: Average 88.9% compression efficiency while maintaining data integrity
- **Rich Metadata Infrastructure**: Comprehensive problem specifications, source provenance, and difficulty annotations

### ğŸš€ **ML-Ready Infrastructure**
- **Automated Data Loading**: Intelligent loaders with format detection and preprocessing capabilities
- **LFS Integration**: Git Large File Storage support for efficient version control of large datasets
- **Batch Processing Support**: Optimized for training pipelines with parallel loading capabilities
- **Cross-Platform Compatibility**: Python 3.8+ support with minimal dependencies

### ğŸ“Š **Research-Grade Quality**
- **Multiple Authoritative Sources**: Datasets from DIMACS challenges, academic benchmarks, and real-world networks
- **Balanced Problem Distribution**: Careful selection across difficulty spectra and structural characteristics
- **Reproducible Results**: Deterministic loading and processing ensuring experimental consistency

## ğŸ“ é¡¹ç›®ç»“æ„

```
CO-Benchmark-Datasets/
â”œâ”€â”€ processed/                      # å¤„ç†åçš„æ•°æ®é›†
â”‚   â”œâ”€â”€ graph_partitioning/        # å›¾åˆ’åˆ†æ•°æ®
â”‚   â”œâ”€â”€ graph_coloring/            # å›¾ç€è‰²æ•°æ®
â”‚   â””â”€â”€ number_partitioning/       # æ•°å€¼åˆ’åˆ†æ•°æ®
â”œâ”€â”€ scripts/                       # æ•°æ®å¤„ç†è„šæœ¬
â”‚   â”œâ”€â”€ unified_loader.py          # ç»Ÿä¸€æ•°æ®åŠ è½½å™¨ï¼ˆæ¨èä½¿ç”¨ï¼‰
â”‚   â”œâ”€â”€ compress_datasets_parallel.py  # å¹¶è¡Œå‹ç¼©è„šæœ¬
â”‚   â””â”€â”€ example_usage.py           # ä½¿ç”¨ç¤ºä¾‹è„šæœ¬
â””â”€â”€ README.md                      # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ¨èæ–¹æ³•ï¼šç»Ÿä¸€æ•°æ®åŠ è½½å™¨

```python
from scripts.unified_loader import load_graph_txt, load_npp_txt, load_instance

# åŠ è½½å›¾æ•°æ®ï¼ˆè‡ªåŠ¨å¤„ç†ç´¢å¼•è½¬æ¢ã€å»é‡å’Œå»è‡ªç¯ï¼‰
graph = load_graph_txt('processed/graph_partitioning/compressed/tiny/dolphins.txt.xz')

# åŠ è½½æ•°å€¼åˆ’åˆ†æ•°æ®
numbers = load_npp_txt('processed/number_partitioning/compressed/small/n025d12e00.txt.xz')

# è‡ªåŠ¨è¯†åˆ«å¹¶åŠ è½½ä»»ä½•ç±»å‹çš„æ•°æ®é›†
instance = load_instance('processed/graph_coloring/compressed/tiny/DSJC125.1.col.txt.xz')
```

### å‘½ä»¤è¡Œä½¿ç”¨

```bash
# ä½¿ç”¨ç»Ÿä¸€åŠ è½½å™¨åŠ è½½å¹¶æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
python3 scripts/unified_loader.py processed/graph_partitioning/compressed/tiny/dolphins.txt.xz --verbose

# è¿è¡Œå®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹
python3 scripts/example_usage.py
```

## ğŸ“Š æ•°æ®é›†æ¦‚è§ˆ

| é—®é¢˜ç±»å‹ | æ•°æ®é›†æ•°é‡ | å‹ç¼©æ¯” | è§„æ¨¡åˆ†ç±» |
|----------|------------|--------|------------|
| å›¾åˆ’åˆ† | 69 | 98.4% | tiny/small/medium/large/xlarge |
| å›¾ç€è‰² | 79 | 82.9% | tiny/small |
| æ•°å€¼åˆ’åˆ† | 300 | 83.3% | tiny/small/medium/large |

## ğŸ¤– ç®—æ³•åŸºå‡†

### å›¾åˆ’åˆ†

- **GNN-A2C å¤šçº§ä¼˜åŒ–æ–¹æ³•**ï¼šç»“åˆç»å…¸å¤šçº§æ¡†æ¶å’ŒA2Cç®—æ³•ï¼Œä½¿ç”¨GNNè¿›è¡Œå±€éƒ¨ä¼˜åŒ–
- **Revolver**ï¼šå»ä¸­å¿ƒåŒ–çš„å¤šæ™ºèƒ½ä½“æ–¹æ³•ï¼Œå°†æ¯ä¸ªé¡¶ç‚¹è§†ä¸ºä¸€ä¸ªæ™ºèƒ½ä½“
- **NeuroCUT (2023)**ï¼šæ”¯æŒä»»æ„kè·¯åˆ’åˆ†å’Œéå¯å¾®ç›®æ ‡çš„GNN+RLæ¡†æ¶
- **PR-GPT (2024)**ï¼šé‡‡ç”¨é¢„è®­ç»ƒ-å¾®è°ƒèŒƒå¼ï¼ŒåŠ é€Ÿå¤§è§„æ¨¡å›¾çš„åˆ’åˆ†

### å›¾ç€è‰²

- **ReLCol**ï¼šä½¿ç”¨DQNå’ŒGNNå­¦ä¹ æ„é€ å¼å¯å‘ç­–ç•¥
- **LOMAC (2024)**ï¼šé€šè¿‡çŠ¶æ€ç©ºé—´é‡æ„å®ç°å¯æ‰©å±•ç€è‰²ï¼Œå¤æ‚åº¦é™è‡³O(NÂ²)
- **æ··åˆæ¡†æ¶**ï¼šç»“åˆæ·±åº¦å­¦ä¹ ä¸è’™ç‰¹å¡æ´›æ ‘æœç´¢æˆ–æ¨¡å› ç®—æ³•

### æ•°å€¼åˆ’åˆ†

- **é¡ºåºå†³ç­–æ¨¡å‹**ï¼šæŒ‰é™åºæ’åˆ—æ•°å­—ï¼Œè®­ç»ƒRLæ™ºèƒ½ä½“åˆ†é…åˆ°å­é›†
- **é€‚ç”¨ç®—æ³•**ï¼šç­–ç•¥æ¢¯åº¦æ–¹æ³•ï¼ˆREINFORCE, PPOï¼‰å’ŒQ-Learningæ–¹æ³•ï¼ˆDQNï¼‰

## ğŸ“š æ•°æ®é›†æ¥æº

### å›¾åˆ’åˆ†
- **DIMACS10 å›¾é›†**ï¼šç¬¬åå±ŠDIMACSå®æ–½æŒ‘æˆ˜èµ›å®˜æ–¹æ•°æ®é›†
- **HypergraphPartitioning**ï¼šVLSIèŠ¯ç‰‡è®¾è®¡é¢†åŸŸçš„è¶…å›¾/å›¾åˆ’åˆ†åŸºå‡†
- **å¼€æ”¾å›¾åŸºå‡† (OGB)**ï¼šç°ä»£åŒ–å¤§è§„æ¨¡å›¾æ•°æ®é›†
- **SuiteSparse & SNAP**ï¼šç§‘å­¦è®¡ç®—å’ŒçœŸå®ä¸–ç•Œç½‘ç»œå›¾å®ä¾‹

### å›¾ç€è‰²
- **DIMACS & COLOR02/03/04**ï¼šå›¾ç€è‰²ç®—æ³•æ€§èƒ½è¯„ä¼°æœ€æƒå¨æ ‡å‡†
- **ROARS Benchmark Instances**ï¼šæ ¼å¼é½å…¨çš„å›¾ç€è‰²åŸºå‡†
- **Network Repository**ï¼šçœŸå®ä¸–ç•Œå’Œåˆæˆç½‘ç»œæ•°æ®ä»“åº“

### æ•°å€¼åˆ’åˆ†
- **Pedroso & Kubo çš„ NPP å®ä¾‹**ï¼šåŸºäºç›¸å˜ç°è±¡ç”Ÿæˆçš„å®ä¾‹
- **Mertens (2003)**ï¼šæ•°å€¼åˆ’åˆ†é—®é¢˜éš¾åº¦ç›¸å˜ç°è±¡çš„ç†è®ºåˆ†æ
- **ç¨‹åºåŒ–ç”Ÿæˆå™¨**ï¼šç”¨æˆ·è‡ªå®šä¹‰å‚æ•°ç”Ÿæˆæ•´æ•°é›†

## ğŸ“– ä½¿ç”¨æŒ‡å—

è¯¦ç»†çš„ä½¿ç”¨æŒ‡å—å’Œæ–‡æ¡£ï¼š

- [`processed/README.md`](processed/README.md)ï¼šå¤„ç†åæ•°æ®é›†çš„è¯¦ç»†è¯´æ˜
- [`scripts/README.md`](scripts/README.md)ï¼šè„šæœ¬ä½¿ç”¨è¯´æ˜
- [`processed/graph_partitioning/README.md`](processed/graph_partitioning/README.md)ï¼šå›¾åˆ’åˆ†æ•°æ®é›†è¯´æ˜
- [`processed/graph_coloring/README.md`](processed/graph_coloring/README.md)ï¼šå›¾ç€è‰²æ•°æ®é›†è¯´æ˜
- [`processed/number_partitioning/README.md`](processed/number_partitioning/README.md)ï¼šæ•°å€¼åˆ’åˆ†æ•°æ®é›†è¯´æ˜

## ğŸ’» ä»£ç è§„èŒƒ

### æ³¨é‡Šè¯­è¨€æ ‡å‡†
æœ¬é¡¹ç›®ç»Ÿä¸€ä½¿ç”¨**ä¸­æ–‡**ä½œä¸ºæ‰€æœ‰ä»£ç æ³¨é‡Šå’Œæ–‡æ¡£çš„è¯­è¨€ï¼Œç¡®ä¿ï¼š

- **å¯è¯»æ€§**ï¼šä¸­æ–‡æ³¨é‡Šä¾¿äºä¸­æ–‡å¼€å‘è€…ç†è§£å’Œç»´æŠ¤ä»£ç 
- **ä¸€è‡´æ€§**ï¼šæ‰€æœ‰Pythonè„šæœ¬ã€Shellè„šæœ¬å’Œæ–‡æ¡£éƒ½é‡‡ç”¨ä¸­æ–‡æ³¨é‡Š
- **ä¸“ä¸šæ€§**ï¼šä¿æŒæŠ€æœ¯æœ¯è¯­çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä½¿ç”¨ä¸­æ–‡è¿›è¡Œè¯´æ˜

#### æ³¨é‡Šç¤ºä¾‹
```python
def mk_data(n, nbits):
    """ç”Ÿæˆæ•°å€¼åˆ’åˆ†çš„éšæœºæ•°æ®ï¼šä½¿ç”¨å…·æœ‰ 'nbits' ä½çš„æ•´æ•°"""
    data = []
    for i in range(n):
        # æ„å»ºå…·æœ‰æŒ‡å®šä½æ•°çš„éšæœºæ•´æ•°
        value = 0
        for b in range(nbits):
            if random.random() >= 0.5:
                value += 2**b
        data.append(value)
    return data
```

```bash
#!/bin/bash
# æ•°æ®é›†å‹ç¼©è„šæœ¬
# ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†ä»¥æé«˜æ•ˆç‡

echo "å¼€å§‹å‹ç¼©æ•°æ®é›†..."
```

### è´¡çŒ®è€…é¡»çŸ¥
å½“å‘æœ¬é¡¹ç›®è´¡çŒ®ä»£ç æ—¶ï¼Œè¯·ç¡®ä¿ï¼š
1. æ‰€æœ‰å‡½æ•°å’Œç±»çš„docstringä½¿ç”¨ä¸­æ–‡
2. è¡Œå†…æ³¨é‡Šä½¿ç”¨ä¸­æ–‡è¯´æ˜ä»£ç é€»è¾‘
3. è„šæœ¬æ–‡ä»¶çš„å¤´éƒ¨è¯´æ˜ä½¿ç”¨ä¸­æ–‡
4. ä¿æŒä¸ç°æœ‰ä»£ç é£æ ¼çš„ä¸€è‡´æ€§

## ğŸ“ˆ é¡¹ç›®çŠ¶æ€

- [x] é¡¹ç›®åˆå§‹åŒ–å’Œæ–‡æ¡£ç¼–å†™
- [x] ç›®å½•ç»“æ„åˆ›å»º
- [x] æ•°æ®å¤„ç†è„šæœ¬å¼€å‘
- [x] æ•°æ®é›†ä¸‹è½½å’Œæ”¶é›†
- [x] æ•°æ®æ ¼å¼æ ‡å‡†åŒ–
- [x] æ•°æ®é›†å‹ç¼©å’Œä¼˜åŒ–
- [x] ç»Ÿä¸€æ•°æ®åŠ è½½å™¨å¼€å‘
- [x] æ–‡æ¡£æ•´ç†å’Œä¼˜åŒ–
- [x] å¤§æ–‡ä»¶åˆ†å—å¤„ç†ï¼ˆGitHub æ–‡ä»¶å¤§å°é™åˆ¶åˆè§„ï¼‰
- [x] é¡¹ç›®æ¸…ç†å·¥ä½œï¼ˆæ·»åŠ .claudeåˆ°.gitignoreï¼Œæ¸…ç†.DS_Storeæ–‡ä»¶ï¼‰
- [ ] è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†åˆ’åˆ†
- [ ] åŸºçº¿ç®—æ³•å®ç°å’Œæµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤é—®é¢˜æŠ¥å‘Šã€åŠŸèƒ½è¯·æ±‚æˆ–æ•°æ®é›†è´¡çŒ®ã€‚è¯·ç¡®ä¿ï¼š

1. æ–°æ•°æ®é›†éµå¾ªç°æœ‰çš„æ ¼å¼æ ‡å‡†
2. åŒ…å«é€‚å½“çš„å…ƒæ•°æ®
3. æ·»åŠ ç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹
4. æ›´æ–°æ–‡æ¡£

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹æ•°æ®é›†å’Œç®—æ³•çš„æä¾›è€…ï¼š

### æ•°æ®é›†æä¾›è€…
- **DIMACSå®æ–½æŒ‘æˆ˜èµ›**ï¼šæä¾›å›¾åˆ’åˆ†å’Œå›¾ç€è‰²é¢†åŸŸçš„æƒå¨åŸºå‡†æ•°æ®é›†
- **SNAPç½‘ç»œæ•°æ®é›†**ï¼šæ–¯å¦ç¦ç½‘ç»œåˆ†æé¡¹ç›®çš„çœŸå®ä¸–ç•Œç½‘ç»œå›¾
- **SuiteSparseçŸ©é˜µé›†åˆ**ï¼šç§‘å­¦è®¡ç®—ä¸­çš„ç¨€ç–çŸ©é˜µç»“æ„å›¾
- **å¼€æ”¾å›¾åŸºå‡†(OGB)**ï¼šä¸ºå›¾æœºå™¨å­¦ä¹ è®¾è®¡çš„ç°ä»£åŒ–å¤§è§„æ¨¡æ•°æ®é›†
- **ROARSé¡¹ç›®**ï¼šæä¾›å¤šç§ç»å…¸å›¾ç€è‰²åŸºå‡†å®ä¾‹
- **HypergraphPartitioningé¡¹ç›®**ï¼šä¸“ä¸ºVLSIèŠ¯ç‰‡è®¾è®¡é¢†åŸŸçš„è¶…å›¾åˆ’åˆ†åŸºå‡†

### ç®—æ³•å’Œè®ºæ–‡ä½œè€…
- **Gatti et al.**ï¼šGNN-A2Cå¤šçº§ä¼˜åŒ–æ–¹æ³•çš„æå‡ºè€…
- **Mofrad et al.**ï¼šRevolverå¤šæ™ºèƒ½ä½“æ–¹æ³•çš„å¼€å‘è€…
- **Lemos et al.**ï¼šReLColå›¾ç€è‰²ç®—æ³•çš„ä½œè€…
- **LOMACå›¢é˜Ÿ**ï¼šçŠ¶æ€ç©ºé—´é‡æ„æ–¹æ³•çš„åˆ›æ–°è€…
- **æ‰€æœ‰ç¥ç»ç»„åˆä¼˜åŒ–å’Œå¼ºåŒ–å­¦ä¹ åœ¨ç»„åˆä¼˜åŒ–é¢†åŸŸåº”ç”¨çš„ç ”ç©¶è€…ä»¬**

---

<div align="center">

**å½“å‰ç‰ˆæœ¬ï¼š1.0.1 (2025-11-06)**

è¯¦ç»†å˜æ›´è®°å½•è¯·å‚è€ƒï¼š[`NextList.md`](NextList.md)

</div>