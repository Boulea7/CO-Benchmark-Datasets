<div align="center">

# ğŸš€ CO-Benchmark-Datasets

**Comprehensive Benchmark Datasets for Reinforcement Learning in Combinatorial Optimization**

[![Version](https://img.shields.io/badge/version-1.0.1-blue.svg)](https://github.com/Boulea7/CO-Benchmark-Datasets)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/)
[![Issues](https://img.shields.io/github/issues/Boulea7/CO-Benchmark-Datasets)](https://github.com/Boulea7/CO-Benchmark-Datasets/issues)
[![Size](https://img.shields.io/github/repo-size/Boulea7/CO-Benchmark-Datasets)](https://github.com/Boulea7/CO-Benchmark-Datasets)
[![Dataset Size](https://img.shields.io/badge/datasets-447%20files-orange.svg)]()

## ğŸ¯ Research Focus: NP-Hard Combinatorial Optimization Problems

**Specialized benchmark datasets for advancing reinforcement learning algorithms in classical NP-Hard problems**

</div>

---

## ğŸ“‹ Abstract

This repository provides a comprehensive collection of standardized, high-quality benchmark datasets specifically designed for evaluating reinforcement learning algorithms on classical combinatorial optimization problems. Our benchmark suite focuses on three fundamental NP-Hard problems that serve as critical testbeds for algorithmic innovation:

- ğŸ”„ **Graph Partitioning** - Minimize cut edges while maintaining balance constraints
- ğŸ¨ **Graph Coloring** - Minimize chromatic number while avoiding adjacent conflicts
- ğŸ”¢ **Number Partitioning** - Balance subset assignments to minimize maximum completion time

These datasets are meticulously curated from multiple authoritative sources, processed into unified formats, and optimized for machine learning workflows, providing the research community with essential tools for developing and evaluating next-generation RL algorithms.


## ğŸ“š Table of Contents

- [Abstract](#-abstract)
- [Key Features](#-key-features)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Dataset Overview](#-dataset-overview)
- [Algorithm Baselines](#-algorithm-baselines)
- [Data Sources](#-data-sources)
- [Usage Guidelines](#-usage-guidelines)
- [Repository Structure](#-repository-structure)
- [Code Standards](#-ä»£ç è§„èŒƒ)
- [License](#-license)
- [Acknowledgments](#-acknowledgments)

## âœ¨ Key Features

### ğŸ”§ **Technical Excellence**
- **Unified Format Standard**: All datasets converted to consistent text format following RLSolver competition specifications
- **Scalable Size Classification**: Systematic categorization (tiny/small/medium/large/xlarge) for progressive algorithm development
- **High Compression Ratio**: Average 88.9% compression efficiency while maintaining data integrity
- **Rich Metadata Infrastructure**: Comprehensive problem specifications, source provenance, and difficulty annotations

### ğŸš€ **ML-Ready Infrastructure**
- **Automated Data Loading**: Intelligent loaders with format detection and preprocessing capabilities
- **LFS Integration**: Git Large File Storage support for efficient version control of large datasets
- **Batch Processing Support**: Optimized for training pipelines with parallel loading capabilities
- **Cross-Platform Compatibility**: Python 3.8+ support with minimal dependencies

### ğŸ“Š **Research-Grade Quality**
- **Multiple Authoritative Sources**: Datasets from DIMACS challenges, academic benchmarks, and real-world networks
- **Balanced Problem Distribution**: Careful selection across difficulty spectra and structural characteristics
- **Reproducible Results**: Deterministic loading and processing ensuring experimental consistency

## ğŸ“ é¡¹ç›®ç»“æ„

```
CO-Benchmark-Datasets/
â”œâ”€â”€ processed/                      # å¤„ç†åçš„æ•°æ®é›†
â”‚   â”œâ”€â”€ graph_partitioning/        # å›¾åˆ’åˆ†æ•°æ®
â”‚   â”œâ”€â”€ graph_coloring/            # å›¾ç€è‰²æ•°æ®
â”‚   â””â”€â”€ number_partitioning/       # æ•°å€¼åˆ’åˆ†æ•°æ®
â”œâ”€â”€ scripts/                       # æ•°æ®å¤„ç†è„šæœ¬
â”‚   â”œâ”€â”€ unified_loader.py          # ç»Ÿä¸€æ•°æ®åŠ è½½å™¨ï¼ˆæ¨èä½¿ç”¨ï¼‰
â”‚   â”œâ”€â”€ compress_datasets_parallel.py  # å¹¶è¡Œå‹ç¼©è„šæœ¬
â”‚   â””â”€â”€ example_usage.py           # ä½¿ç”¨ç¤ºä¾‹è„šæœ¬
â””â”€â”€ README.md                      # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ¨èæ–¹æ³•ï¼šç»Ÿä¸€æ•°æ®åŠ è½½å™¨

```python
from scripts.unified_loader import load_graph_txt, load_npp_txt, load_instance

# åŠ è½½å›¾æ•°æ®ï¼ˆè‡ªåŠ¨å¤„ç†ç´¢å¼•è½¬æ¢ã€å»é‡å’Œå»è‡ªç¯ï¼‰
graph = load_graph_txt('processed/graph_partitioning/compressed/tiny/dolphins.txt.xz')

# åŠ è½½æ•°å€¼åˆ’åˆ†æ•°æ®
numbers = load_npp_txt('processed/number_partitioning/compressed/small/n025d12e00.txt.xz')

# è‡ªåŠ¨è¯†åˆ«å¹¶åŠ è½½ä»»ä½•ç±»å‹çš„æ•°æ®é›†
instance = load_instance('processed/graph_coloring/compressed/tiny/DSJC125.1.col.txt.xz')
```

### å‘½ä»¤è¡Œä½¿ç”¨

```bash
# ä½¿ç”¨ç»Ÿä¸€åŠ è½½å™¨åŠ è½½å¹¶æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
python3 scripts/unified_loader.py processed/graph_partitioning/compressed/tiny/dolphins.txt.xz --verbose

# è¿è¡Œå®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹
python3 scripts/example_usage.py
```

## ğŸ“Š æ•°æ®é›†æ¦‚è§ˆ

| é—®é¢˜ç±»å‹ | æ•°æ®é›†æ•°é‡ | å‹ç¼©æ¯” | è§„æ¨¡åˆ†ç±» |
|----------|------------|--------|------------|
| å›¾åˆ’åˆ† | 69 | 98.4% | tiny/small/medium/large/xlarge |
| å›¾ç€è‰² | 79 | 82.9% | tiny/small |
| æ•°å€¼åˆ’åˆ† | 300 | 83.3% | tiny/small/medium/large |

## ğŸ¤– ç®—æ³•åŸºå‡†

### å›¾åˆ’åˆ†
- **[GNN-A2C å¤šçº§ä¼˜åŒ–æ–¹æ³•](https://www.jmlr.org/papers/volume23/21-0644/21-0644.pdf)** (JMLR 2022)
- **[Revolver](https://arxiv.org/abs/1907.06768)** (IEEE CLOUD 2018)
- **[NeuroCUT](https://arxiv.org/abs/2310.11787)** (2023)
- **[PR-GPT](https://arxiv.org/abs/2409.00670)** (2024)

### å›¾ç€è‰²
- **[ReLCol](https://arxiv.org/abs/2304.04051)** (2023)
- **[LOMAC](https://openreview.net/pdf?id=49a2a85d60c6055f0607ba775a412c10a87aa7a0)** (ICLR 2024)
- **[GNN + DQN](https://arxiv.org/pdf/1903.04598)** (2019)
- **[MCTS + DRL](https://link.springer.com/article/10.1007/s10878-025-01338-8)** (2025)

### æ•°å€¼åˆ’åˆ†
- **[Neural CO with RL](https://arxiv.org/abs/1704.01916)** (2017)
- **[RL for CO Survey](https://arxiv.org/abs/2003.03600)** (2020)
- **[RL for NP-hard](https://arxiv.org/abs/1905.06393)** (2019)

## ğŸ“š æ•°æ®é›†æ¥æº

### å›¾åˆ’åˆ†
- **[DIMACS10 å›¾é›†](http://www.cc.gatech.edu/dimacs10/index.shtml)** - ç¬¬åå±ŠDIMACSå®æ–½æŒ‘æˆ˜èµ›å®˜æ–¹æ•°æ®é›†
- **[HypergraphPartitioning](https://github.com/TILOS-AI-Institute/HypergraphPartitioning)** - VLSIèŠ¯ç‰‡è®¾è®¡é¢†åŸŸåŸºå‡†
- **[å¼€æ”¾å›¾åŸºå‡† (OGB)](https://ogb.stanford.edu/)** - ç°ä»£åŒ–å¤§è§„æ¨¡å›¾æ•°æ®é›†
- **[SuiteSparse](https://sparse.tamu.edu/)** - ç§‘å­¦è®¡ç®—ç¨€ç–çŸ©é˜µç»“æ„å›¾
- **[SNAP æ•°æ®é›†](https://snap.stanford.edu/data/)** - çœŸå®ä¸–ç•Œç½‘ç»œå›¾

### å›¾ç€è‰²
- **[DIMACS & COLOR02/03/04](https://mat.tepper.cmu.edu/COLOR/instances.html)** - å›¾ç€è‰²ç®—æ³•æƒå¨æ ‡å‡†
- **[ROARS Benchmark](https://roars.dev/npbench/graphcoloring.html)** - æ ¼å¼é½å…¨çš„å›¾ç€è‰²åŸºå‡†
- **[Network Repository](https://networkrepository.com/dimacs.php)** - çœŸå®ä¸–ç•Œå’Œåˆæˆç½‘ç»œ

### æ•°å€¼åˆ’åˆ†
- **[Pedroso & Kubo NPP](https://www.dcc.fc.up.pt/~jpp/partition/readme.html)** - åŸºäºç›¸å˜ç°è±¡çš„æ ‡å‡†å®ä¾‹
- **[Mertens (2003) ç†è®º](https://arxiv.org/pdf/cond-mat/0310317)** - éš¾åº¦ç›¸å˜ç°è±¡ç†è®ºåˆ†æ

## ğŸ“– ä½¿ç”¨æŒ‡å—

è¯¦ç»†çš„ä½¿ç”¨æŒ‡å—å’Œæ–‡æ¡£ï¼š

- [`processed/README.md`](processed/README.md)ï¼šå¤„ç†åæ•°æ®é›†çš„è¯¦ç»†è¯´æ˜
- [`scripts/README.md`](scripts/README.md)ï¼šè„šæœ¬ä½¿ç”¨è¯´æ˜
- [`processed/graph_partitioning/README.md`](processed/graph_partitioning/README.md)ï¼šå›¾åˆ’åˆ†æ•°æ®é›†è¯´æ˜
- [`processed/graph_coloring/README.md`](processed/graph_coloring/README.md)ï¼šå›¾ç€è‰²æ•°æ®é›†è¯´æ˜
- [`processed/number_partitioning/README.md`](processed/number_partitioning/README.md)ï¼šæ•°å€¼åˆ’åˆ†æ•°æ®é›†è¯´æ˜

## ğŸ’» ä»£ç è§„èŒƒ

### æ³¨é‡Šè¯­è¨€æ ‡å‡†
æœ¬é¡¹ç›®ç»Ÿä¸€ä½¿ç”¨**ä¸­æ–‡**ä½œä¸ºæ‰€æœ‰ä»£ç æ³¨é‡Šå’Œæ–‡æ¡£çš„è¯­è¨€ï¼Œç¡®ä¿ï¼š

- **å¯è¯»æ€§**ï¼šä¸­æ–‡æ³¨é‡Šä¾¿äºä¸­æ–‡å¼€å‘è€…ç†è§£å’Œç»´æŠ¤ä»£ç 
- **ä¸€è‡´æ€§**ï¼šæ‰€æœ‰Pythonè„šæœ¬ã€Shellè„šæœ¬å’Œæ–‡æ¡£éƒ½é‡‡ç”¨ä¸­æ–‡æ³¨é‡Š
- **ä¸“ä¸šæ€§**ï¼šä¿æŒæŠ€æœ¯æœ¯è¯­çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä½¿ç”¨ä¸­æ–‡è¿›è¡Œè¯´æ˜

#### æ³¨é‡Šç¤ºä¾‹
```python
def mk_data(n, nbits):
    """ç”Ÿæˆæ•°å€¼åˆ’åˆ†çš„éšæœºæ•°æ®ï¼šä½¿ç”¨å…·æœ‰ 'nbits' ä½çš„æ•´æ•°"""
    data = []
    for i in range(n):
        # æ„å»ºå…·æœ‰æŒ‡å®šä½æ•°çš„éšæœºæ•´æ•°
        value = 0
        for b in range(nbits):
            if random.random() >= 0.5:
                value += 2**b
        data.append(value)
    return data
```

```bash
#!/bin/bash
# æ•°æ®é›†å‹ç¼©è„šæœ¬
# ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†ä»¥æé«˜æ•ˆç‡

echo "å¼€å§‹å‹ç¼©æ•°æ®é›†..."
```

### è´¡çŒ®è€…é¡»çŸ¥
å½“å‘æœ¬é¡¹ç›®è´¡çŒ®ä»£ç æ—¶ï¼Œè¯·ç¡®ä¿ï¼š
1. æ‰€æœ‰å‡½æ•°å’Œç±»çš„docstringä½¿ç”¨ä¸­æ–‡
2. è¡Œå†…æ³¨é‡Šä½¿ç”¨ä¸­æ–‡è¯´æ˜ä»£ç é€»è¾‘
3. è„šæœ¬æ–‡ä»¶çš„å¤´éƒ¨è¯´æ˜ä½¿ç”¨ä¸­æ–‡
4. ä¿æŒä¸ç°æœ‰ä»£ç é£æ ¼çš„ä¸€è‡´æ€§

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹æ•°æ®é›†å’Œç®—æ³•çš„æä¾›è€…ï¼š

### æ•°æ®é›†æä¾›è€…
- **DIMACSå®æ–½æŒ‘æˆ˜èµ›**ï¼šæä¾›å›¾åˆ’åˆ†å’Œå›¾ç€è‰²é¢†åŸŸçš„æƒå¨åŸºå‡†æ•°æ®é›†
- **SNAPç½‘ç»œæ•°æ®é›†**ï¼šæ–¯å¦ç¦ç½‘ç»œåˆ†æé¡¹ç›®çš„çœŸå®ä¸–ç•Œç½‘ç»œå›¾
- **SuiteSparseçŸ©é˜µé›†åˆ**ï¼šç§‘å­¦è®¡ç®—ä¸­çš„ç¨€ç–çŸ©é˜µç»“æ„å›¾
- **å¼€æ”¾å›¾åŸºå‡†(OGB)**ï¼šä¸ºå›¾æœºå™¨å­¦ä¹ è®¾è®¡çš„ç°ä»£åŒ–å¤§è§„æ¨¡æ•°æ®é›†
- **ROARSé¡¹ç›®**ï¼šæä¾›å¤šç§ç»å…¸å›¾ç€è‰²åŸºå‡†å®ä¾‹
- **HypergraphPartitioningé¡¹ç›®**ï¼šä¸“ä¸ºVLSIèŠ¯ç‰‡è®¾è®¡é¢†åŸŸçš„è¶…å›¾åˆ’åˆ†åŸºå‡†

### ç®—æ³•å’Œè®ºæ–‡ä½œè€…
- **Gatti et al.**ï¼šGNN-A2Cå¤šçº§ä¼˜åŒ–æ–¹æ³•çš„æå‡ºè€…
- **Mofrad et al.**ï¼šRevolverå¤šæ™ºèƒ½ä½“æ–¹æ³•çš„å¼€å‘è€…
- **Lemos et al.**ï¼šReLColå›¾ç€è‰²ç®—æ³•çš„ä½œè€…
- **LOMACå›¢é˜Ÿ**ï¼šçŠ¶æ€ç©ºé—´é‡æ„æ–¹æ³•çš„åˆ›æ–°è€…
- **æ‰€æœ‰ç¥ç»ç»„åˆä¼˜åŒ–å’Œå¼ºåŒ–å­¦ä¹ åœ¨ç»„åˆä¼˜åŒ–é¢†åŸŸåº”ç”¨çš„ç ”ç©¶è€…ä»¬**

---

<div align="center">

**å½“å‰ç‰ˆæœ¬ï¼š1.0.1 (2025-11-06)**

è¯¦ç»†å˜æ›´è®°å½•è¯·å‚è€ƒï¼š[`NextList.md`](NextList.md)

</div>